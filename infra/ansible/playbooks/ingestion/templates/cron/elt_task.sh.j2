#!/usr/bin/env bash
set -euo pipefail

# Constants
ELT_GIT_URL={{ ingestion_elt_git_url }}
ELT_GIT_DEST={{ ingestion_elt_git_dest }}
ELT_GIT_REF=main
EXTRACT_AND_LOAD_SCRIPT=extract_and_load.py
LOG_LEVEL=DEBUG
ON_PIPELINE_FAILURE=log_and_continue
REQUIREMENTS_TXT=requirements.txt
SPARK_CONF_DIR={{ ingestion_spark_conf_dir }}

function ensure_elt_sources_exist() {
  export GIT_TERMINAL_PROMPT=0
  if [ -d "$ELT_GIT_DEST" ]; then
    pushd $ELT_GIT_DEST
    git clean -d -x --force
    git reset --hard
    git checkout "$ELT_GIT_REF"
    git pull
    popd
  else
    git clone $ELT_GIT_URL $ELT_GIT_DEST
    git checkout "$ELT_GIT_REF"
  fi
}

# Script arguments - directories are relative to ELT_GIT_DEST
# As many dbt project directories can be passed as required
if [ $# -eq 0  ]; then
  echo "Usage $0 <extract_and_load_dir> [dbt_project_dir] [dbt_run_args...]"
  exit 1
fi
extract_and_load_dir=$1
dbt_project_dir=${2:-}
shift 2
ensure_elt_sources_exist

# Extraction
cd $ELT_GIT_DEST/$extract_and_load_dir
uv run \
  --reinstall \
  --script $EXTRACT_AND_LOAD_SCRIPT \
  --log-level $LOG_LEVEL \
  --on-pipeline-step-failure $ON_PIPELINE_FAILURE

# Transform
if [ -n "$dbt_project_dir" ]; then
  cd $ELT_GIT_DEST/$dbt_project_dir
  uv venv
  uv pip install -r requirements/$REQUIREMENTS_TXT
  export SPARK_CONF_DIR
  uv run \
    dbt run $*
fi
